---
title       : Determining Population Parameters for Mixtures of Normal Distributions
subtitle    : 
author      : John Montgomery-Brown
job         : Coursera
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : github      # 
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
---

## Problem: Estimating Population Parameters for Subpopulations within a Data Set

With most environmental and/or geologic samples, it is fairly rare to obtain samples that are comprised of a single population. For example, 
- soil at a site may contain background levels of a particular analyte and also be contaminated by an anthropogenic source of the same analyte.
- ore may contain veinlets of pure mineral (e.g., copper) and other material with lower concentrations of the analyte of interest.

To obtain accurate estimates of the parameters of interest (i.e., the degree of contamination due to anthropogenic activities, the average grade of a precious metal deposit), it is essential to be able to identify (e.g., background versus contaminated) and characterize (e.g., estimate the population mean and standard deviation) the subpopulations within a given data set.

--- .class #id 

## Problem: Estimating Population Parameters for Subpopulations within a Data Set

While the importance of accurately characterizing the subpopulations within a data set is clearly recognized within the [mining industry](http://books.google.com/books?id=oo7rCrFQJksC&pg=PA173&lpg=PA173&dq=mixture+normal+distributions+sinclair&source=bl&ots=-uBTeXjIR4&sig=KZxWDsCq7BJbroM5FFoVk3kHFjs&hl=en&sa=X&ei=txlxVLWnJIj9iAKjq4G4BA&ved=0CC4Q6AEwAw#v=onepage&q=mixture%20normal%20distributions%20sinclair&f=false) (where the misclassification of recoverable grade and tonnage can lead to significant economic losses), this characterization is less frequently performed in the field of environmental remediation. 

As a result, few tools have been developed to assist environmental professionals with this type of analysis. 

--- .class #id 

## Shiny Application

For this project, I have developed a [Shiny Application](https://jmbekd.shinyapps.io/Developing_Data_Projects/) that guides users through the process of:
- investigating and transforming (if necessary) the original data, and 
- selecting inflection points on a QQ plot to separate the mixture of subpopulations into the component subpopulations.

Using this information the [Shiny application](https://jmbekd.shinyapps.io/Developing_Data_Projects/) 
- uses the `normalmixEM` [expectation-maximization](http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm) function within the `mixtools` package to estimate maximum likelihood population parameters for the subpopulations, and 
- simulates example data sets from the estimated population parameters for comparison against the original dataset. 

Additional details on transforming the data and selecting inflection points are presented on the following slide.

--- &twocol w1:35% w2:65%

## Non-Normality and Inflection Points 

*** =left 

### Non-Normality

Distributions of concentration data for many analytes are rarely normally distributed.
- Can transform the data set to make approximately normal.
- Concentration data for analytes of environmental concern or minerals of economic significance commonly approximate [lognormal distributions](http://en.wikipedia.org/wiki/Log-normal_distribution) and hence, can be modeled as normal distributions by log-transforming the data.

*** =right 

### Inflection Points

For simple mixtures, histograms and density plots of the data may be used to graphically determine the population parameters for each subpopulation. 
- For more complex mixtures, it is often easier to estimate the relative proportions of each subpopulation from the [inflection points](http://en.wikipedia.org/wiki/Inflection_point) (change in direction of curvature) on a [QQ plot](http://en.wikipedia.org/wiki/Q%E2%80%93Q_plot) of the data and to partition the data using this/these estimate.

```{r echo = FALSE, fig.height = 4, fig.width = 4, fig.align = "center"}
percents <- c(0.01, 0.1, 1, 2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 98, 99, 99.9, 99.99)
n <- 10000
propA <- 0.65
A <- sort(exp(rnorm(n, 4, 0.75)))
B <- sort(exp(rnorm(n, 6, 0.25)))
i_mix <- sort(c(sample(A, size = propA * n), sample(B, size = (1 - propA) * n)))
mix <- qqnorm(log(i_mix), plot.it = FALSE)
par(mar = c(5.1, 4.1, 3.1, 2.1), oma = c(0, 0, 0, 0))
plot(mix, 
     col = 0, 
     type = "l",
     lwd = 2,
     cex = 0.5, 
     xlim = c(-3, 3), 
     ylim = c(2, 7), 
     xaxt = "n",
     yaxt = "n",
     xlab = "Cumulative Frequency %", 
     ylab = "log Concentration",
     main = "QQ Plot of a Mixture of \nTwo Lognormal Populations")
points(as.data.frame(mix)[length(mix$x) * percents / 100, ], cex = 1)
lines(mix, col = "black", lwd = 2)
lines(qqnorm(log(A), plot.it = FALSE), col = "blue", lwd = 1)
lines(qqnorm(log(B), plot.it = FALSE), col = "green", lwd = 1)
axis(1, at = qnorm(percents / 100), labels = as.character(percents), cex.axis = 0.6)
axis(2, at = seq(2, 7, by = 0.5), labels = NA)
legend("topleft", inset = 0.02, 
       c("A + B", "A", "A"), lty = c(1, 1, 1), lwd = c(2, 1, 1), 
       col = c("black", "green", "blue"), text.col = c("black", "green", "blue"), bty = "n", cex = 0.8)
abline(v = qnorm(propA), col = "red", lwd = 2, lty = 2)
points(qnorm(65 / 100), 5.58, col = "red", pch = 19, cex = 1.5)
text(qnorm(60 / 100), 5, "Inflection\nPoint", col = "red", adj = c(1, -0.70), cex = 0.8)
```



